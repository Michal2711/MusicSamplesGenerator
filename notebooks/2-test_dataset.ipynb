{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "from data.audio_dataset import AudioSpectrogramDataset\n",
    "import soundfile as sf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = AudioSpectrogramDataset(base_directory=\"../data/raw/nsynth-train/audio\", spectro_type='mel')\n",
    "item0 = dataset.__getitem__(0)\n",
    "item1 = dataset.__getitem__(1)\n",
    "item2 = dataset.__getitem__(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 256, 160])\n",
      "torch.Size([1, 256, 160])\n",
      "torch.Size([1, 256, 160])\n"
     ]
    }
   ],
   "source": [
    "print(item0.shape)\n",
    "print(item1.shape)\n",
    "print(item2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 256, 160])\n"
     ]
    }
   ],
   "source": [
    "DataSize = dataset.get_data_size()\n",
    "print(DataSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 0, spectro: torch.Size([16, 1, 256, 160])\n",
      "i: 1, spectro: torch.Size([16, 1, 256, 160])\n",
      "i: 2, spectro: torch.Size([16, 1, 256, 160])\n",
      "i: 3, spectro: torch.Size([16, 1, 256, 160])\n",
      "i: 4, spectro: torch.Size([16, 1, 256, 160])\n",
      "i: 5, spectro: torch.Size([16, 1, 256, 160])\n",
      "i: 6, spectro: torch.Size([16, 1, 256, 160])\n",
      "i: 7, spectro: torch.Size([16, 1, 256, 160])\n",
      "i: 8, spectro: torch.Size([16, 1, 256, 160])\n",
      "i: 9, spectro: torch.Size([16, 1, 256, 160])\n",
      "i: 10, spectro: torch.Size([16, 1, 256, 160])\n",
      "i: 11, spectro: torch.Size([16, 1, 256, 160])\n"
     ]
    }
   ],
   "source": [
    "for i, spectro in enumerate(dataloader):\n",
    "    print(f'i: {i}, spectro: {spectro.shape}')\n",
    "    if(i>10): break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 256, 160])\n",
      "torch.Size([1, 256, 160])\n",
      "torch.Size([1, 256, 160])\n",
      "torch.Size([1, 256, 160])\n",
      "torch.Size([1, 256, 160])\n",
      "torch.Size([1, 256, 160])\n",
      "torch.Size([1, 256, 160])\n",
      "torch.Size([1, 256, 160])\n",
      "torch.Size([1, 256, 160])\n",
      "torch.Size([1, 256, 160])\n",
      "torch.Size([1, 256, 160])\n",
      "torch.Size([1, 256, 160])\n",
      "torch.Size([1, 256, 160])\n",
      "torch.Size([1, 256, 160])\n",
      "torch.Size([1, 256, 160])\n",
      "torch.Size([1, 256, 160])\n"
     ]
    }
   ],
   "source": [
    "for s in spectro:\n",
    "    print(s.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot interpret 'torch.float32' as a data type",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\0. Studia\\0. Praca inzynierska\\Music_Samples_Generator\\notebooks\\2-test_dataset.ipynb Cell 9\u001b[0m line \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/0.%20Studia/0.%20Praca%20inzynierska/Music_Samples_Generator/notebooks/2-test_dataset.ipynb#X12sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mlibrosa\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/0.%20Studia/0.%20Praca%20inzynierska/Music_Samples_Generator/notebooks/2-test_dataset.ipynb#X12sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m10\u001b[39m, \u001b[39m5\u001b[39m))\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/0.%20Studia/0.%20Praca%20inzynierska/Music_Samples_Generator/notebooks/2-test_dataset.ipynb#X12sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m img \u001b[39m=\u001b[39m librosa\u001b[39m.\u001b[39;49mdisplay\u001b[39m.\u001b[39;49mspecshow(spectro, x_axis\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mtime\u001b[39;49m\u001b[39m'\u001b[39;49m, y_axis\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mlog\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/0.%20Studia/0.%20Praca%20inzynierska/Music_Samples_Generator/notebooks/2-test_dataset.ipynb#X12sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m plt\u001b[39m.\u001b[39mtitle(\u001b[39m'\u001b[39m\u001b[39mWGAN_generated_spectrogram\u001b[39m\u001b[39m'\u001b[39m, fontsize\u001b[39m=\u001b[39m\u001b[39m20\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/0.%20Studia/0.%20Praca%20inzynierska/Music_Samples_Generator/notebooks/2-test_dataset.ipynb#X12sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m plt\u001b[39m.\u001b[39mcolorbar(img, \u001b[39mformat\u001b[39m\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m%0.2f\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\librosa\\display.py:1173\u001b[0m, in \u001b[0;36mspecshow\u001b[1;34m(data, x_coords, y_coords, x_axis, y_axis, sr, hop_length, n_fft, win_length, fmin, fmax, tuning, bins_per_octave, key, Sa, mela, thaat, auto_aspect, htk, unicode, intervals, unison, ax, **kwargs)\u001b[0m\n\u001b[0;32m    924\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mspecshow\u001b[39m(\n\u001b[0;32m    925\u001b[0m     data: np\u001b[39m.\u001b[39mndarray,\n\u001b[0;32m    926\u001b[0m     \u001b[39m*\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    949\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[0;32m    950\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m QuadMesh:\n\u001b[0;32m    951\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Display a spectrogram/chromagram/cqt/etc.\u001b[39;00m\n\u001b[0;32m    952\u001b[0m \n\u001b[0;32m    953\u001b[0m \u001b[39m    For a detailed overview of this function, see :ref:`sphx_glr_auto_examples_plot_display.py`\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1171\u001b[0m \u001b[39m    >>> fig.colorbar(img, ax=ax, format=\"%+2.f dB\")\u001b[39;00m\n\u001b[0;32m   1172\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1173\u001b[0m     \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39;49missubdtype(data\u001b[39m.\u001b[39;49mdtype, np\u001b[39m.\u001b[39;49mcomplexfloating):\n\u001b[0;32m   1174\u001b[0m         warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m   1175\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mTrying to display complex-valued input. \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mShowing magnitude instead.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1176\u001b[0m             stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[0;32m   1177\u001b[0m         )\n\u001b[0;32m   1178\u001b[0m         data \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mabs(data)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\numpy\\core\\numerictypes.py:417\u001b[0m, in \u001b[0;36missubdtype\u001b[1;34m(arg1, arg2)\u001b[0m\n\u001b[0;32m    359\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    360\u001b[0m \u001b[39mReturns True if first argument is a typecode lower/equal in type hierarchy.\u001b[39;00m\n\u001b[0;32m    361\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    414\u001b[0m \n\u001b[0;32m    415\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    416\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m issubclass_(arg1, generic):\n\u001b[1;32m--> 417\u001b[0m     arg1 \u001b[39m=\u001b[39m dtype(arg1)\u001b[39m.\u001b[39mtype\n\u001b[0;32m    418\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m issubclass_(arg2, generic):\n\u001b[0;32m    419\u001b[0m     arg2 \u001b[39m=\u001b[39m dtype(arg2)\u001b[39m.\u001b[39mtype\n",
      "\u001b[1;31mTypeError\u001b[0m: Cannot interpret 'torch.float32' as a data type"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "img = librosa.display.specshow(spectro, x_axis='time', y_axis='log')\n",
    "plt.title('WGAN_generated_spectrogram', fontsize=20)\n",
    "plt.colorbar(img, format='%0.2f')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 88064)\n"
     ]
    },
    {
     "ename": "LibsndfileError",
     "evalue": "Error opening 'new_librosa-mel.wav': Format not recognised.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLibsndfileError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32mc:\\0. Studia\\0. Praca inzynierska\\Music_Samples_Generator\\notebooks\\2-test_dataset.ipynb Cell 8\u001b[0m line \u001b[0;36m9\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/0.%20Studia/0.%20Praca%20inzynierska/Music_Samples_Generator/notebooks/2-test_dataset.ipynb#X10sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m path \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/0.%20Studia/0.%20Praca%20inzynierska/Music_Samples_Generator/notebooks/2-test_dataset.ipynb#X10sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m path \u001b[39m=\u001b[39m path \u001b[39m+\u001b[39m name\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/0.%20Studia/0.%20Praca%20inzynierska/Music_Samples_Generator/notebooks/2-test_dataset.ipynb#X10sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m sf\u001b[39m.\u001b[39;49mwrite(path, audio, \u001b[39m22050\u001b[39;49m, subtype\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mPCM_24\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\soundfile.py:343\u001b[0m, in \u001b[0;36mwrite\u001b[1;34m(file, data, samplerate, subtype, endian, format, closefd)\u001b[0m\n\u001b[0;32m    341\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    342\u001b[0m     channels \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n\u001b[1;32m--> 343\u001b[0m \u001b[39mwith\u001b[39;00m SoundFile(file, \u001b[39m'\u001b[39;49m\u001b[39mw\u001b[39;49m\u001b[39m'\u001b[39;49m, samplerate, channels,\n\u001b[0;32m    344\u001b[0m                subtype, endian, \u001b[39mformat\u001b[39;49m, closefd) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m    345\u001b[0m     f\u001b[39m.\u001b[39mwrite(data)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\soundfile.py:658\u001b[0m, in \u001b[0;36mSoundFile.__init__\u001b[1;34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd)\u001b[0m\n\u001b[0;32m    655\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mode \u001b[39m=\u001b[39m mode\n\u001b[0;32m    656\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_info \u001b[39m=\u001b[39m _create_info_struct(file, mode, samplerate, channels,\n\u001b[0;32m    657\u001b[0m                                  \u001b[39mformat\u001b[39m, subtype, endian)\n\u001b[1;32m--> 658\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_file \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_open(file, mode_int, closefd)\n\u001b[0;32m    659\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mset\u001b[39m(mode)\u001b[39m.\u001b[39missuperset(\u001b[39m'\u001b[39m\u001b[39mr+\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseekable():\n\u001b[0;32m    660\u001b[0m     \u001b[39m# Move write position to 0 (like in Python file objects)\u001b[39;00m\n\u001b[0;32m    661\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseek(\u001b[39m0\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\soundfile.py:1216\u001b[0m, in \u001b[0;36mSoundFile._open\u001b[1;34m(self, file, mode_int, closefd)\u001b[0m\n\u001b[0;32m   1213\u001b[0m \u001b[39mif\u001b[39;00m file_ptr \u001b[39m==\u001b[39m _ffi\u001b[39m.\u001b[39mNULL:\n\u001b[0;32m   1214\u001b[0m     \u001b[39m# get the actual error code\u001b[39;00m\n\u001b[0;32m   1215\u001b[0m     err \u001b[39m=\u001b[39m _snd\u001b[39m.\u001b[39msf_error(file_ptr)\n\u001b[1;32m-> 1216\u001b[0m     \u001b[39mraise\u001b[39;00m LibsndfileError(err, prefix\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mError opening \u001b[39m\u001b[39m{0!r}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname))\n\u001b[0;32m   1217\u001b[0m \u001b[39mif\u001b[39;00m mode_int \u001b[39m==\u001b[39m _snd\u001b[39m.\u001b[39mSFM_WRITE:\n\u001b[0;32m   1218\u001b[0m     \u001b[39m# Due to a bug in libsndfile version <= 1.0.25, frames != 0\u001b[39;00m\n\u001b[0;32m   1219\u001b[0m     \u001b[39m# when opening a named pipe in SFM_WRITE mode.\u001b[39;00m\n\u001b[0;32m   1220\u001b[0m     \u001b[39m# See http://github.com/erikd/libsndfile/issues/77.\u001b[39;00m\n\u001b[0;32m   1221\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_info\u001b[39m.\u001b[39mframes \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "\u001b[1;31mLibsndfileError\u001b[0m: Error opening 'new_librosa-mel.wav': Format not recognised."
     ]
    }
   ],
   "source": [
    "audio = dataset.pipeline.post_process(item0)\n",
    "name = f'new_librosa-{dataset.spectro_type}.wav'\n",
    "\n",
    "path = '../models/generated_samples/'\n",
    "path = path + name\n",
    "\n",
    "sf.write(path, audio, 22050, subtype='PCM_24')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
